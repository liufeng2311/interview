### Redis的知识结构

* 知识结构

       线程模型、淘汰策略、过期机制、持久化方式、数据结构、功能应用、集群部署   

* 参考链接

       http://www.redis.cn/documentation.html   官网
       https://aobing.blog.csdn.net/article/details/103041932  博客
       https://www.cnblogs.com/javazhiyin/p/13839357.html 博客

### 缓存

* 为什么使用缓存

       使用缓存是高并发场景下提高热点数据访问性能的一中有效手段。用以提高系统的响应速度。
       对于关系型数据库,数据是保存在磁盘中的,将数据从磁盘加载至JVM中需要磁盘IO和网络IO,这一过程是耗时的。
       我们可以将热门数据提前加载至JVM中以达到快速调用的效果,这就是缓存。

* 缓存的分类

       本地缓存
       
           JVM中的数据可以理解为本地缓存,不需要通过网络IO和磁盘IO就可以通过程序直接获得。
           本地缓存在多个JVM实例间不能互享。
           
       分布式缓存
       
           分布式缓存用来解决多个JVM不能共享内存数据的,比如Redis,不需要进行磁盘IO,只需要经过网络IO。
           多个JVM通过共同访问统一内存实现数据共享。
           
       多级缓存
       
           多级缓存只是一种策略,根据数据的访问频率不同将数据存储在不同的地方,最热门数据存储到本地缓存中,较热门数据存储到
           分布式缓存中,冷门数据存储在关系型数据库中 

### Redis

* 什么是Redis

       Redis是基于C编写的高性能非关系型的键值对数据库。与关系型数据库不同,Redis的值是存储在内存中的。
       这就意味着他的读写速度非常的快,官方测试数据为单核每秒10万次读写操作。

* redis线程模型

       Redis的网络通信是用NIO实现的。通过一个多路复用线程来处理接受到的channel请求。
       seleter会将请求暂存起来顺序执行。类似于Netty单线程版本。
       Redis的单线程指的是只有一个线程来处理用户请求,而不是整个redis只有一个线程。


* 单线程的redis如何提高CPU的利用率

       可以通过部署多个redis实例来提高利用率
       也可以部署其他的服务

* 为什么Redis的读写速度快

       redis的读写是完全基于内存的,数据的读写耗时可以基本定义为网络数据传输的耗时。
       redis的数据结构简单,数据的读写耗时基本可以忽略。
       redis采用单线程的处理机制,避免了单线程的上下文切换。

### Redis是单线程还是多线程？

    我们经常说Redis是单线程指的是Redis中命令的读写是单线程执行的, 并不是说Redis内部只有一个线程。
    redis6.0之前 网络数据的读写、协议解析、内存命令的读写都是由主线程执行的。
    redis6.0之后 网络数据的读写、协议解析使用多线程处理, 但内存命令的读写依旧由主线程执行。

### 缓存淘汰策略

* 淘汰策略

       基于内存存储数据必定受限于内存大小。
       当剩余内存不足以保存我们的新数据时,需要通过某些策略删除一些数据。这就是数据淘汰策略。

* 常用淘汰策略算法

      FIFO : 删除最早存入的数据,实现方式为队列
               
      LRU : 删除最久未使用的数据,实现方式为双向链表
       
      LFU ：删除访问频率最低的数据,实现方式为大顶堆


### Redis服务部署

* 下载redis安装包

       Redis官方下载最新版本安装包并上传服务器(https://redis.io/download)
       安装redis的环境(yum install gcc)
       进入解压后的文件进行编译和安装(make & make install)
           
       make :该指令的目的是为了编译redis,生成可执行文件,此时只能在src目录下启动服务(未配置环境变量)
       make install: 将常用命令放至/usr/local/bin目录下,此时可以在系统任何位置启动服务(配置环境变量)

* 单机部署

       修改配置文件redis.conf
           
       bind : 设置redis使用的网卡地址,表示外界只有访问该网卡才可以访问redis,可配置多个网卡IP
       port : 设置redis服务的端口
       daemonize : 设置为yes,表示以守护线程启动(后台启动)
       pidfile : 存储redis实例IP,修改为安装包路径即可
       dir : 存储数据的地址,修改为安装包路径即可
       logfile : 日志路径,修改为安装包路径即可
       requirepass : 设置登录密码
       
      开放端口
     
      firewall-cmd --zone=public --add-port=6379/tcp --permanent   开放6379端口
      firewall-cmd --reload  重新加载防火墙规则使配置生效
      
      启动服务
      
      redis-server redis.conf

* 主从复制(主节点出错的话,需要手动切换节点)

      全量同步：
      1. 指定主服务的IP地址、端口、密码
         replicaof IP port   设置replicaof指向master的IP和端口(Redis 5.0 之前使用 slaveof)
         masterauth 123456   设置master的密码
      2. 建立链接后从服务会发送同步指令到主服务
         psync ？-1
         psync有两个参数
         第一个参数表示该从库连接的主库的表示, ? 表示该节点没有和任何主库进行关联
         第二个参数表示该从库目前的消息偏移量, -1 表示未同步任何消息
      3. 主库接收到从库的指令后, 告知从库主库的唯一表示(psync的第一个参数)、当前的偏移量
      4. 主库fork出子线程执行bgave命令生成RDB文件并传送至从库
      5. 从库下载RDB文件,清空内存并加载RDB文件(此时可对外提供服务),
      6. 主库会缓存主库RDB生成、从库RDB记载期间新的命令到replication buffer缓存区(每个从库一个)并发送给从库。至此全量同步结束
      7. 之后主从会建立一条长链接不断接收主库发送的消息
      
      疑问??????
      1. 上述第6点主库发送replication buffer过程中又会有新的写消息进入, 具体如何切换为命令传播
      2. 命令传播时消息时如何保证有序的, 同步发送是如何保证的

      增量同步:
      网络抖动造成的短时间数据丢失需要使用增量同步来实现, 主库存在一块圆形区域缓存repl_backlog_buffer,从库
      通过psync runId offest去repl_backlog_buffer查找缺失的数据, 如果缓存中不存在该部分区域,则触发全量同步。


* 哨兵模式(所有节点的密码必须是一致的)(主节点出错的话,哨兵完成切换)

      哨兵模式是为了弥补主从复制需要手动切换的缺陷,通过哨兵监控完成主从切换,默认配置一主二从三哨兵。
      哨兵中配置了master节点的地址和密码(哨兵从master节点读取slave节点的信息),
      当超过半数以上的哨兵认为master节点宕机了,就修改其中一个slave节点为master节点,
      并修改其他从节点的配置文件指向该master节点
     
      修改配置文件sentinel.conf(主从复制基础上添加哨兵配置)
           
      sentinel monitor master 192.168.0.104 6379 2  指定主节点的IP、端口, 2表示至少两个哨兵同意才能进行故障转移,过半原则,哨兵最少为三个
      sentinel auth-pass master <password>     设置主节点密码

* 集群部署(只有master可以提供读写功能,slave不提供读写功能,只保证高可用)(强一致性)

  修改配置文件redis.conf(单机版基础上)

           cluster-enabled yes 开启集群
           cluster-node-timeout 5000  超时时间设置为5秒,超过则认为连接失败   

  启动所有实例
  创建集群(至少三个master节点)

           redis-cli --cluster create IP1:port1 IP2:port2 IP3:port3 IP4:port4 IP5:port5 IP6:port6 --cluster-replicas 1  最后的1表示分配比例,主从按1:1分配,前三个为主机
  查看集群帮助文档

           redis-cli --cluster help

  客户端连接

           redis-cli -h IP -p port -c       -c是redis-cli独有的,可以跳转到对应的服务器

### redis数据结构

* 字典
  Redis的数据结构被称为字典,字典是hash算法的一种实现。类似于java中的HashMap。

       字典包含了如下字段:
           
           1. 数据的类型
           2. Hash表(两个hash表,一个用于扩容)
           3. 是否在扩容标志
           4. 当前正在运行的安全迭代器数量  

### redis有哪些常见的使用场景,在实际项目中使用到过那些场景

* 常见的场景

      1. 分布式锁
      2. C端接口缓存数据存储、权限信息缓存
      3. 游戏排行榜、学生分数表、接口调用数排名
      4. 计数功能
      5. 附近的人
      6. 人员签到信息统计

* 项目中的使用

      1. 接口数据缓存
      2. 分布式锁
      3. 权限数据缓存
### Redis五种数据类型的创建规则

    list、set、hash、sortedset都属于容器型数据库, 共同遵守如下规则
    create if not exists;
    drop if no elements;

### Reids

    Redis是KV键值对, 我们可以为K设置过期时间, 不可以为V中的数据项设置过期时间。
    当我们重新对K进行赋值时,原有的过期时间会失效。
### String

* 定义

      String类型是Redis中使用最多的类型之一, 所有的key都使用的该类型, 该类型最多可以存储512M的数据。
      Redis中的String也叫做动态字符串(Simple Dynamic String),简称SDS。是二进制安全的字符串。
      Redis中的String支持追加数据, 扩容时, 当前容量小于1M时, 采用加倍扩容策略, 当前容量超过超过1M时, 每次增加1M。
      Redis中的String虽然是动态字符串,但是创建时默认不会分配冗余空间,因为绝大多数场景使用不到追加的特性,会造成空间浪费。

* 为什么不直接使用C语言的字符串

      最主要的原因是C语言的字符串不是二进制安全的,C语言以NULL(0x\0)表示字符串的结尾,但是很多二进制数据本身就包含NULL(0x\0),就会导致读取到的数据丢失。
      其次C语言的字符串没有保存字符串的长度, 每次获取时都需要遍历字符, 时间复杂度较高。

* Redis对象头

      Redis对象头保存了对象的运行信息, 包含如下信息5个信息, 共占用16个字节。
      1. type      对象的类型(4bit)
      2. encoding  对象的编码格式(4bit)
      3. refcount  对象的引用次数(4bytes)
      4. lru       对象的LRU信息(24bit)
      5. *ptr      真实数据的引用(8bytes)

      我们可以通过如下命令查看对象存储信息
      debug object < key>

* SDS数据结构

      主要包含三个属性:
      T capacity        底层数组的容量
      T len             实际数据占用的容量
      byte[] content    存储的数据

* Redis中的String的编码

      字符串的编码主要有三种
      int        表示存储的为数字, 可进行数字相关操作, 有效值的区间为有符号数long的区间
      embstr     表示存储的为短字符串(44个字符以内), redis对象头和SDS存储在一起(系统分配一次空间)
      raw        表示存储的为长字符串(44个字符串以上), redis对象头和SDS分开存储(系统需要分配两次空间)

      为什么分界线是44个字符串？
      类似于java中的对象都有Java对象头, redis中的对象也都redis对象头,对象头信息占用16个字节。SSD中非数据信息占用了3个字节,
      字符串的结尾标识(0x\0)占用一个字节, 这些信息共占用20个字节。操作系统内存分配器一次分配的最大内存单位为64个字节,
      64-20=44, 也就是说44个字节(包含)以下只需要分配一次内存,44个字节以上需要多次分配内存。

* 命令定义

      SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-time|KEEPTTL] [NX|XX] [GET]
     
      基本命令为SET key value, 同时提供了三个附加参数: 设置过期时间、设置生效条件、获取当前值

      设置过期时间
      EX        设置生效的秒数
      PX        设置生效的毫秒数
      EXAT      设置有效期至当前时间戳(秒)
      PXAT      设置有效期至当前时间戳(毫秒)
      KEEPTTL   继续沿用之前的过期时间(对于已存在的key, 重新设置值会导致之前设置的过期时间生效, 该参数可以沿用之前的过期时间)

      设置生效条件
      NX        之前不存在key则生效
      EX        之前存在key则生效

      获取当前值
      GET       该命令会返回当前key的值

* 使用场景

      1. 缓存序列化的用户信息(经常用于保存权限信息,用于每次请求的验证)
      2. 缓存接口的结果信息
      3. 计数功能
      4. 分布式锁
      5. 表单防重复提交

### List

* 定义

        List记录了元素的顺序, 通过先进先出可以实现队列, 也可以通过先进后出实现盏。 
        早期版本数据少时使用ziplist实现,数据多时,使用linkedlist实现,后期改为quicklist实现。
        数据较少时(8K),使用ziplist存储,数据较多时,使用quicklist实现。

* linkedlist、ziplist、quicklist的区别

      linkedlist中的每个节点仅保存一个数据,每个节点通过前后索引来关联前后节点。
      ziplist是一块连续的内存,内存中的数据紧密排列,各个节点不需要使用前后索引来关联前后节点。
      quicklist是linkedlist和ziplist的合体,元素节点为ziplist,各个节点通过前后索引关联,quicklist主要是用于防止ziplist过大导致新增元素时频繁复制的问题。

* ziplist数据结构

      ziplist是一块连续的内存空间,空间中的数据紧密相连,除了数据外,还保存了一些状态信息:
      zlbytes          节点所占用的字节数
      zltail_offest    最后一个节点的偏移量(可以快速定位最后一个元素,实现倒叙查询)
      zllength         元素个数
      zlend            节点结束标识
      T[] entries      元素数组

      元素结构
      prevlen          前一个元素的字节长度(倒叙查询使用,可以定位前一个元素的起点)
      encoding         元素类型编码
      byte[] content   元素

* quicklist数据

      quicklist通过前后节点连接元素,每个元素都是ziplist, 通过ziplist减少指针空间消耗,又通过指针减少ziplist扩容时的频繁复制问题。

* 使用场景

      1. 可以用作队列
      2. 可以用作栈

### Hash

* 定义

      类似与java中的HashMap

* 扩容

      元素达到数组长度则进行扩容, 采用渐进式扩容, 当访问该hash时, 搬运该槽位的数据即可。
      一直不访问hash时, 由定时任务主动触发。

* 缩容

      元素仅有数组长度的10%时
* 场景

      1. 保存用户的各项信息
      2. 保存商品的各项信息
      3. 商品促销中各个商品的个数
      4. 限时用的领奖次数

### Set

* 定义

      Set的实现依赖的Hash,只不过value的值都为null

* 场景

      共享好友

### SortedSet

* 定义

      SortedSet是对Set能力的提升, 为Set中的每个元素关联一个分数,通过分数就可以对Set中的元素进行排序。
      SortedSet中的元素依旧不可以重复, 但元素关联的分数却可以重复。

* 数据结构

      SortedSet是通过跳跃链表实现的, 所有的元素都位于最底层,由于是通过链表实现的, 无法通过二分查找快速定位, 于是采用
      空间换时间的方法,让底层一半的元素抽取到第二层,第二层在抽取到第三层,从而达到二分的目的。
      
      通过hashMap保证元素的不重复, 通过跳表链表保证元素按照分数排序。

* 比较算法

      如果当所有元素的分数都一样, 排序也就无意义了, 因此排序时是通过(分数+内容排序的)

* 使用场景

      1. 游戏分数榜
      
      2. 学生成绩榜
      
      3. 商场每天产品销量排行
     
      4. 广告每天点击次数排行

      5. 话题热度

### BitMap

* 定义

      BitMap通过操作计算机内部最小的存储单元(Bit)实现了一种内存高效信息的数据结构。每一个Bit都可以代表一种独立的状态。
      BitMap底层使用的是字符串,因此最大为512G

* 使用场景

      1. 统计用户签到
      
      2. 每天活跃用户ID
    
      3. 优惠券每人限领一张

* 需求场景

      1. 统计用户每月签到情况, 对签到超过20天的用户发放奖励
      2. 发放一批优惠券, 要求每个用户只能领取一张

* 问题

      1. 直接使用redis的BitMap设置数据通过Java中的BitSet转换后数据混乱

* 代码

### Redis持久化

* Redis持久化

       Redis是基于内存的数据库,重启后会造成数据的丢失。因此需要持久化。redis提供了两种持久化方式：
       RDB(Redis DataBase): 指定时间间隔对数据进行快照。
       AOF(Append Only File): 记录每次对服务器写的操作。   
       4.0后提供了混合持久化。RDB+RDB期间的增量AOF。

* RDB(默认开启)

       save 900 1              900秒发生1次变化就保存
       save 300 10             300秒发生10次变化就保存
       save 60  10000          60秒10000次变化就保存
       save ""                 关闭RDB持久化方式

* AOF(默认关闭)

       appendfsync always      每个命令都写入
       appendfsync everysec    每秒写入一次
       appendfsync no          关闭AOF持久化方式


* redis重启如何加载数据

       当我们只配置一种持久化方式时,会加载我们配置的文件
       当我们两种都配置时,只会加载AOF中的数据,因为AOF保存的信息总是比RDB全面

* RDB和AOF的比较

       RDB相对于AOF来说文件更小,因为RDB是对实时数据的快照,AOF是对命令的拼接。一条数据新增和删除
       在RDB中是体现不出来的,而AOF中会保留下记录。
       AOF相对RDB来说保存的数据更全面,默认只丢失一秒的数据。
       为了解决AOF文件偏大的问题,当文件过大时,后台会触发AOF重写,减小文件的大小

* 选用哪种持久化方式

       最好两个都开启,RDB方便数据的备份,我们可以每天或者每小时进行数据备份
       AOF用以保存完整的数据 

* Redis如何保证RDB持久化时不会丢失新增的数据?

      Redis持久化时通过COW机制实现了数据不丢失, 为了不影响线上的请求, Redis会fork出一个子线程来进行RDB,
      此时子线程和主线程的内存是共享的, 此时如果主线程发生数据修改, 会将数据所在的页复制一份来修改, 这就保证了
      子线程RDB期间的数据是不变的, 复制完成后再把增量数据进行复制即可。
*

### Redis持久化数据和缓存怎么做扩容

* 搭建集群扩容

       Redis集群提供了扩容机制,我们可以把没有数据的槽点分配给新的redis服务

### 使用redis作为缓存会存在什么问题

* 数据不一致问题

       1.正常情况
           
           正常情况我们先修改数据库,然后更新缓存,这个过程分为三步：
           1. 更新数据
           2. 更新缓存
           
           上述过程中存在如下两种情况:
           1. 更新数据库失败的话,缓存依旧为最新的数据,不会造成数据不一致
           2. 更新数据库成功,更新缓存失败,导致缓存中的数据不正确,造成数据不一致
           
       2. 当数据库更新成功缓存更新失败
           
           为了解决上述问题中的不一致,可以在更新数据库前直接删除缓存再更新数据库再更新缓存

       3. 解决办法
           
           设置一个标志位,当执行增删改操作成功后,设置该标志位为false,当更新缓存后设置为true
           当查询时,只有标志位为true才可以查询,否则自旋

* 高并发下的数据不一致问题

        1. 删除缓存再更新数据库再更新缓存会存在如下问题
           
           在并发量高的情况下,可能存在读线程在写线程执行前又把旧的数据缓存起来,所以写线程更新后需要再次删除缓存,
           由下一个读线程更新缓存。

* 缓存穿透(恶意攻击和爬虫)

       描述
       
           一直访问数据库不存在的数据,导致缓存失去意义, 具体又可以分为两种情况
              情况一: 访问一个不存在的数据
              情况二: 访问不同的不存在的数据
       解决办法
           
           对于情况一, 我们通过缓存一个空值就可以很好的解决, 但很明显这种情况不适用情况二, 因为如果缓存大量的不存在的数据, 就会导致浪费很多内存, 
           此时我们需要使用布隆过滤器, 我们将有效的数据全量加载至布隆过滤器中, 这样就可以过滤绝大多数不存在的数据,此时在对漏网之鱼缓存即可。
           即使这样被大量访问无效数据也是致命的,通过风控过滤该IP才是王道。

       布隆过滤器的常见场景
           过滤垃圾邮件、防止恶意攻击
* 缓存击穿

       描述
       
           高并发环境下,缓存失效时刚好有大量读线程同时判断出缓存为空会去访问数据库

       解决办法
           
           查询数据库时添加锁
           热点数据永不过期
* 缓存雪崩

       描述
           
           同一时刻,多个缓存过期,导致大量读线程访问数据库。
           
       解决办法
           
           不同的K设置不同的过期时间,通过添加一个随机数来实现
           加锁来保证同时只有一个线程访问数据库
           分布式部署

### keys命令和scan命令

* keys

      keys命令需要遍历所有的数据, 此时会阻塞其他的命令, 当K值很多时可能导致redis暂时不能处理其他命令

* scan

      由于keys命令需要一次遍历所有的数据, scan对其进行了优化, 采用分段遍历的方式来减小对其他请求的影响 
      
      scan cursor [MATCH pattern] [COUNT count] [TYPE type]
      
      cursor表示槽位索引,意思是我们从当前索引开始遍历数据, 第一次遍历传入0, 每次会返回当前遍历到哪个槽位的索引
      match表示匹配规则
      count表示需要返回的元素数, 这个只是一个预估值
      type表示返回哪个类型的k

### 分布式锁的实现

* Redis为什么支持分布式锁

      redis采用单线程的方式处理接收来的请求,所有的请求都是顺序执行的,不存在多线程并发问题
      处理字符串的NX机制可以判断在没有值K的时候才会去创建,正好对应了无锁时进行加锁的机制

* A线程锁过期后但执行逻辑未结束,此时B线程获取锁执行, 但在执行过程中A线程执行完毕释放了B线程的锁

      上述场景也是锁的一个错误示例, 我们通常在加锁时生成一个随机数, 释放锁时, 根据存储的随机数来释放锁, 可以解决该问题
* 若业务出错无法释放锁如何处理

      默认会给锁一个过期时间,指定时间内锁没有释放的话会自动释放锁,服务异常的话也会自动释放锁
      通过看门狗的机制进行处理方法的执行时间大于默认锁时间的问题,每隔一个时间,看门狗进行一次检测,若方法还在执行,则增加过期时间

* 若master节点宕机且slave节点没有同步该锁时如何处理

      在一台master节点上加锁可能会导致主节点宕机从节点未同步的情况,这样slave变master节点其他请求就能获取到锁了
      处理方式是同时在多台master上加锁,因为多台服务同时宕机的概率极低(过半原则)

* redLock

       RedissonRedLock是redis官方提出的分布式锁实现类,使用与集群环境,在所有的master节点上加锁。
       默认获取失败后没有重试机制。

* key竞争如何解决

       当多个JVM对同一个key操作时,如果需要保证有序性,需要通过分布式锁来确保Key的有序性

### 过期数据的删除策略

* Redis中存在过期时间的数据是如何存储的

       Redis中存在专门的字典用来保存设置了过期时间的数据
       expires字典的K值保存的是指向键空间某个键的指针,V保存的是过期的具体时间

* Redis如何删除过期的数据

       定时删除：设置过期时间时创建一个定时器来删除(对内存非常友好,但是会占用CPU资源)
       定期删除：定期删除过期值,在expires字典中每十秒随机选出20个K进行检测,当过期的数量超过25%,循环该步骤(定期删除)
       惰性删除：获取数据时再判断该数据是否过期,对CPU友好,但是会造成内存浪费

* Redis采用的何种策略

       定期删除 + 惰性删除 + 内存淘汰

* redis如何设置过期时间

       expire key time    设置指定时间
       persist key        设置为不过期
       ttl key            查看剩余存活时间

### 淘汰策略

* Redis内存大小

       maxmemory    该参数指定了redis内存的最大值,该超过该值时,redis如何处理就是所谓的回收算法    
                    设置为0代表没有内存限制。对于64位的系统这是个默认值，对于32位的系统默认内存限制为3GB。

* 内存回收

       redis中的内存是以页为单位的,只要页上存在数据, 所在的页就不会回收, redis已经使用内存也不会减少,
       但我们新增的数据会分配在这些未回收的页上, 内存并不会增加。通过flushdb可以强制回收。

* 设置淘汰策略

       maxmemory-policy       该参数指定了采用哪种算法
       maxmemory-samples 5    设置每次采样数量

* 常用淘汰策略

       noeviction         当需要空闲内存时存储数据时返回错误信息
       allkeys-lru        回收最旧未使用的数据 
       volatile-lru       回收最少使用的数据 ,仅在设置了过期时间的数据中进行删除
       allkeys-random     随机回收数据 
       volatile-random    随机回收数据 ,仅在设置了过期时间的数据中进行删除
       volatile-ttl       回收设置了过期时间且剩余存活时间较短的数据 

* Redis的LRU是如何实现的

       LRU是Redis唯一支持的回收方法,却不是真正意义上的LRU,而是通过采样的方式LRU
       
       当我们存入新的数据时会判断是否会超过内存限制,超过的话会根据我们设置的回收策略进行回收
       通过我们设置测采样数随机的取出指定数量的数据,根据淘汰策略删除数据

### 主从间的数据如何复制

* slave从master复制数据的逻辑

       每个master上都有一个replication ID,标记指定的数据集
       当存在salve时,master会通过offset记录所有的数据
       
       master会保存每个slave已经转移的偏移量,当slave掉线重连后,master会根据已经转移的偏移量进行转移
       replication + offest表示一个集合,记录了数据的多个版本,版本信息存在内存中到达一定值会被清除
       
       slave重连时,如果replication + offest的版本在内存中,只需要转移增量部分, 否则全量转移


* 主从复制过程

       1.slave启动后根据配置的master信息与master建立连接
       2.连接建立后发送sync命令给master表示需要同步数据
       3.master接受到命令后根据replication ID和偏移量来判断是进行全量复制还是增量复制
       4.master生成RDB文件发送给slave同时缓存新接受的命令
       5.slave保存RDB文件并加载后,master同步期间接受的新命令给slave

* redis赋值如何处理key的过期(从服务器如何处理过期)

       slave不会让key过期，而是等待master让key过期。
       当一个master让一个key到期(或由于LRU算法将之驱逐),它会合成一个DEL命令并传输到所有的slave。


* master不开启持久化会存在什么问题,如何解决

       当master关闭持久化时,所有的数据只存在内存中,此时重启会会造成数据全部丢失。
       当slave开启持久化时,在master快速重启后,slave检测到master数据为空,会同步master数据造成数据丢失

### 实现一个淘汰算法,删除最早添加的元素或者删除最久未被访问的元素

* LinkedHashMap实现删除最早添加的数据

       LinkedHashMap默认的淘汰策略是删除最早添加的元素,只不过触发条件为永远返回的fasle
       我们需要重写removeEldestEntry方法,当超过指定数量时,返回true即可。

* LinkedHashMap实现删除最旧未被访问数据

       LinkedHashMap也为我们提供了删除最久未被访问的策略,默认是关闭的,我们通过有参构造函数开启
       LinkedHashMap map = new LinkedHashMap(16, 0.75f, true);

### 布隆该过滤器

* 什么是布隆过滤器

       布隆过滤器指的是在一定误差率的前提下用较小的空间判断某一元素是否存在。
       当返回true时,指定的元素可能并不存在,但是当返回false时,指定的元素一定不存在。

* 布隆过滤器的原理

       布隆过滤器底层通过计算机中最小的单位位(Bit)来实现,使得其可以用较小的空间存储较多的数据。
       类似hashmap,通过将元素进行hash运算确定元素的位置,不同的是,布隆过滤器通过多个hash函数进行定位.
       只有一个元素的所有hash定位的值都为1时,该值才可能存在,有一个不为1,则该值一定不存在
       hash函数的数量和位图的长度决定了误差率的大小。

* 应用场景

       新闻客户端推送新的内容。
       邮箱系统垃圾短信的过滤。
       秒杀活动接口的防刷。

* redis的实现

       Redis中布隆过滤器的底层实现是bitmap,redis提供了java客户端工具类(单节点布隆过滤器)
       
       Config config = new Config();
       config.useSingleServer().setAddress("redis://192.168.14.104:6379");
       config.useSingleServer().setPassword("123");
       RedissonClient redisson = Redisson.create(config);
       RBloomFilter<String> bloomFilter = redisson.getBloomFilter("phoneList");
       bloomFilter.tryInit(100000000L,0.03);
       bloomFilter.add("10086");
       System.out.println(bloomFilter.contains("123456"));//false
        
       Google中布隆过滤器实现
       
       BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01); 
       bloomFilter.put("10086");
       bloomFilter.mightContain("123456")

### HyperLogLog(不理解其原理、后续再理解)

* 什么是HyperLogLog

       HyperLogLog是Redis对基数算法的实现。
       bitmapmap虽然也能用于判断元素是否出现,但是不适合大数据场景,因此出现了HyperLogLog

* 应用场景

      50亿个电话号码,现有10万个电话号码,如何判断这10万个是否已经存在在50亿个之中。

### Redis发布订(消息队列)

* list实现(一对一)

      通过List集合来实现,比如左进右出和右进左出,默认是不支持消费者等待的
      我们可以使用blpop来实现等待

* 发布订阅模式(一对多)(消息多播)

      publish topic  context   发布消息
      subscribe topic          订阅消息

* 消息多播

       消息多播指的是当有多个消费者时, 会生成多个消息队列, 每次队列里的消息是一样的, 但是每个消费者消费速度不一样
       多个消费者直接互不影响。

* redis发布订阅的缺点

      redis发布订阅的数据缓存空间是定的,数据量过大会造成数据丢失
      当消费者断线重连后会造成数据丢失,因为redis没有提供持久化机制
      redis当连接处于空闲状态(60s)时会进行断开, 因此代码中需要捕获异常并重新订阅 

### Redis事务和管道

* 管道的定义

      多条命令一起发送至服务端执行, 执行完毕后统一返回。

* 事务的定义

      事务是一个单独的操作,事务中的命令都会被序列化后按顺序的执行。不会被其他的命令打断。
      但是事务不具备原子性, Redis的事务只保证了所有命令一起执行,但其中有执行失败的并不会回滚。
      multi     开始事务
      exec      执行事务(执行事务中的命令,在此之前的任务都是不执行的)
      discard   放弃事务(丢弃事务中的命令)

* Lua脚本

       Lua脚本也是事务的一种实现,将脚本中的多个命令序列化为一个发送给Redis服务器。

* 事务+管道

      事务需要同时执行多个命令, 如果命令一条条通过网络IO发送至服务器端，效率很差, 我们可以借助管道一次性发送至服务端。

### Redis集群模式(服务端路由查询)

* 什么是集群模式

       哨兵模式下,master节点只有一个,所有的写操作都会在该节点上操作。
       集群模式采用了服务端Sharding技术,通过分区的思想将写操作打散到几个不同
       的写节点上。提高了写节点的能力。
       redis集群只能选择0号数据库。

* 集群模式原理

       通过hash的方式将数据分片,每个写节点负责一部分hash值,默认分配了16384 个槽位。
       可以动态的添加节点(前提是存在未被使用的hash槽),删除节点是必须保证该节点的所有hash槽位
       没有数据。
       
       集群架构下的每个redis节点需要开发两个端口,6379和16379。
       16379用于集群中各个节点的信息通讯。            

### Redis Sharding和Redis Cluster的区别

* 区别
  Redis Sharding是在客户端进行hash找到具体redis实例
  Redis Cluster是在服务端进行hash通过路由找到具体实例

### 生产环境中的redis如何赋值

* 部署

       生产环境下主从机器需要部署在不同的服务器上, 以十台机器为例, 五台部署主机，舞台部署从机,建设每台主机
       qps是5w/s,五台就是25w/s。
       
       每个redis的内存设置为10G最好。

### 热点数据和冷数据

* 什么样的数据需要缓存

      当天的新闻消息(读多写少)
      微博排名和热点值(读多写多)

* 热点数据

      我们需要对热点数据进行统计, 可以将热点数据由查询MySQL改成查询Redis, 也可以将热点数据缓存到本地缓存中。


### redis集群的问题

* 强制指定集群solt

      集群会导致很多redis命令失效, 我们可以通过{prefix}来强制指定数据落到统一集群

### 大k问题

### 双写一致性

* mysql和redis的双写一致性

      1. 强一致性
         强一致性必须加锁, 先修改mysql, 在修改redis, redis失败时mysql回滚。
      2. 最终一致性
         要实现最终一致性的话,我们需要依赖消息中间件或者mysql数据库的binlog日志。

* 双删更新缓存的问题

  双删策略无论如何都没办法避免多线程环境下的不一致问题。

### 如何实现限流

* 限流的常见实现方式由哪些

      固定窗口、滑动窗口、漏桶、令牌桶

* 固定窗口和滑动窗口

      固定窗口指的是在一段固定的时间内只允许通过指定数量的请求,但存在临界值问题。具体场景如下: 
      假设系统1s内仅能处理100条请求,如果在旧窗口的后0.5s收到100个请求,此时窗口变化,我们在新窗口前0.5s又收到100个请求,此时就会超出系统的可处理能力。
      滑动窗口就是为了解决固定窗口的该问题。每次统计的是近1分钟的,这样的话就不会出现上述问题了。

* 漏桶算法

      漏桶算法指的是设置一个固定大小的池,当池中有位置时,请求则进入,否则丢弃。池中的数据按照顺序被取出并执行。
      最新的一批数据肯定会被执行,桶满后的数据不保证顺序性

* 令牌桶算法

      令牌桶算法指的是令牌以均速产生,请求到来时拿到令牌则执行,否则抛弃, 该算法不保证先到先得。

### Redis是如何回收内存的

       redis中数据是以页的形式记录的(16K), 只要页上存在数据, 该页内存就不会回收, 新增数据时依旧会使用这些页。
       以此会出现删除数据发现内存使用率不减少、增加数据内存使用率不增加。
       redis使用惰性删除+定期删除的策略来清理内存中过期的数据。
       惰性删除: 获取数据时进行, 如果数据量小则采用同步删除, 否则采用异步删除。 
       定期删除: 采用同步的方式进行, 每6ms进行一次, 一次扫描20个K, 如果过期数大于25%则触发新的一轮, 每次删除操作最多执行25ms

### 如何在redis中找出固定前缀的K

      我们使用scan命令来查找,命令如下：scan 0 match prefix:* count 1000 , 我们循环调用该方法, 直到返回的索引为0

### 如何使用redis做异步队列和延迟队列

### 缓存降级

    当缓存服务器发生异常时,我们需要提供降级策略, 也就是说当缓服务器异常时, 不再访问缓存服务器, 直接返回降级数据。
